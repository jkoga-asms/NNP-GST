概要
====

GeSbTeは“相変化材料”として知られている。低温でアモルファス状態のGeSbTeは，温度を上げることによって結晶化させることができる。その後さらに温度を上げ，急冷させるとアモルファス状態に戻すことができる。このような特性から，記憶媒体など様々な用途で応用がなされている。

本件ではGeSbTeのニューラルネットワークポテンシャル (neural-network
potential, NNP)
を作成した。液相・アモルファス相・立方晶のGeSbTe系が記述可能で，melt
quenchシミュレーションを行うことができ，アモルファス相から結晶に転移する様子がとらえられるポテンシャルが得られることを目標とした。

本稿ではどのようにニューラルネットワークポテンシャルを作成したか説明する。また，ニューラルネットワークポテンシャルを用いた分子動力学シミュレーションを実行する方法について具体的に解説する。

ニューラルネットワークポテンシャルについて
==========================================

本件で作成したニューラルネットワークポテンシャルについて簡単に説明する。詳しくは文献[1],
[2]などを参照されたい。

ニューラルネットワークポテンシャルとは，その名が示す通り原子間ポテンシャルをニューラルネットワークによって記述するものである。ニューラルネットワークとは入力層・任意の数の隠れ層・出力層からなるネットワークである。各層は任意の数のノードからなり，さらにバイアス層が紐づけられている。
$i$ 番目の層における $j$ 番目のノードの出力 $y _ {i}^{j}$ は， $i - 1$ 番目の層の $k$ 番目のノードの出力 $y _ {k}^{j - 1}$ を入力として以下のように計算される。

$$y _ {i}^{j} = f _ {i}^{j}\\left( b _ {i}^{j} + \\sum _ {k = 1}^{N _ {j - 1}}{w _ {k,i}^{j - 1,j}y _ {k}^{j - 1}} \\right)$$

ここで $w _ {k,i}^{j - 1,j}$ は $j - 1$ 番目の層の $k$ 番目のノードと $j$ 番目の層の $i$ 番目のノードとの間の重み係数， $b _ {i}^{j}$ は $j$ 番目の層の $i$ 番目のノードに対するバイアス層からの寄与である。
$w _ {k,i}^{j - 1,j}$ や $b _ {i}^{j}$ が教師データを再現するよう学習によって決める量である。
$f _ {i}^{j}$ は $j$ 番目の層が $i$ 番目のノードにもたらす作用を表すactivation functionと呼ばれる関数である。
通常activation functionとしては何らかの非線形性を持つ関数が用いられる。
また，非常に小さいか大きい値に対しては-1, 1, 0などの値に収束する性質をもつ。
具体的にはシグモイド関数やガウス関数などが用いられる。出力層においては線形の関数が用いられる場合もある。
なお，「0番目の層の出力」とはすなわち入力ベクトルのことである。
出力層における出力はただ一つの値であり，そのニューラルネットワークポテンシャルに紐づいている原子のエネルギーに対応する。

ニューラルネットワークによって原子間ポテンシャルを表現する場合，その入力ベクトルは原子配置に関連するものであるが，原子配置のxyz座標をそのまま利用することはできない。
これは，原子座標はたとえば原子の入れ替えや全体の回転などの操作に対して不変ではないからである。
そこで，保たれるべき不変性が保たれるsymmetry functionという関数が用いられる場合が多い。
たとえば以下のような関数が用いられる。

$$G _ {i}^{2} = \\sum _ {j = 1}^{N _ {\\text{atom}}}{{\\exp \\left \\lbrack - \\eta _ {2} \\left( r _ {\\text{ij}} - R _ {s} \\right)^{2} \\right \\rbrack}{f _ {c} \\left( r _ { \\text{ij}} \\right)}}$$

$$G _ {i}^{3} = 2^{1 - \\zeta} \\sum _ {j \\neq i}^{}{\\sum _ {k \\neq i,j}^{}{\\left( 1 + \\lambda \\cos \\theta _ {\\text{ijk}} \\right)^{\\zeta} \\exp \\left \\lbrack - \\eta _ {3} \\left\\{ \\left(r _ {\\text{ij}}-r_s\\right)^{2} + \\left(r _ {\\text{ik}}-r_s\\right)^{2} + \\left(r _ {\\text{jk}}-r_s\\right)^{2} \\right\\} \\right \\rbrack f _ {c} \\left( r _ {\\text{ij}} \\right)f _ {c} \\left( r _ {\\text{ik}} \\right)f _ {c} \\left( r _ {\\text{jk}} \\right)}}$$

$G _ {i}^{2}$ は $i$ 番目の原子に対する2体のsymmetry functionである。
$r _ \\text{ij}$ は原子ij間の距離であり， $\\eta _ 2$ や $R _ s$ はこのsymmetry functionの特性を決める係数である。
$f _ {c}( r _ {\\text{ij}} )$ はカットオフ関数であり，カットオフ距離に近づくにつれ0へなめらかに減衰する関数が用いられる。
$G _ {i}^{3}$ は $i$ 番目の原子に対する3体のsymmetry functionである。
$\\theta _ {\\text{ijk}}$ は原子ijkの成す角度であり， $\\eta _ {3}$, $\\lambda$, $\\zeta$ がこのsymmetry functionの特性を決める係数である。
Symmetry functionは異なる $\\eta _ {2}$, $\\eta _ {3}$, $R _ {s}$, $\\lambda$, $\\zeta$ を持つものをいくつ用意してもよい。多く用意すればそれだけ多様な原子配置を表現することができるが，当然計算負荷は高くなる。記述したい系の違いをなるべくうまく差別化できるように選べることが望ましい。
Symmetry functionの選び方の指針は，たとえば文献[3], [4]などにおいて提案されている。

ニューラルネットワークは通常一つ一つの原子に与えられ，それによってその原子のエネルギーが計算される。このようにして求められた各原子のエネルギーの和がその系のエネルギーとなる。第一原理計算においては通常エネルギーは全系のものがただ一つ求まるのでこの分け方は便宜的なものととらえることもできるが，原子ごと（元素ごと）にニューラルネットワークを割り当てることによって教師データとして用いた系とは異なる原子数（場合によっては異なる化学量論比）の系に対しても適用できるようになるというメリットがある。

ニューラルネットワークポテンシャルはうまく作成すれば第一原理計算の結果を原子当たり1
meVの精度で再現できる高精度な手法である。他方なんらかの物理的なモデルに基づくものではないため，教師データの“外挿”は不得手としている。排除体積効果さえも含まれないので，うまくいかない場合は極端に短い結合が現れるなど分子動力学シミュレーションとして破綻してしまうような場合もある点がデメリットである。

ニューラルネットワークポテンシャルの作成
========================================

ニューラルネットワークポテンシャルの作成方法
--------------------------------------------

ニューラルネットワークポテンシャルを作成するためには，「教師データ」が必要となる。これは原子座標データと対応する全エネルギーと場合によっては原子間力である。このデータは第一原理分子動力学シミュレーションの軌跡から得ることが多い。ニューラルネットワークポテンシャルは教師データの外挿は苦手なので，適用したい領域を包含する原子配置を教師データとして採用する必要がある。

教師データからニューラルネットワークポテンシャルを作成するソフトウェアとして
n2p2 (https://github.com/CompPhysVienna/n2p2), ænet
(http://ann.atomistic.net/), deepmd
(https://github.com/deepmodeling/deepmd-kit) などがある。本件ではn2p2
[5]を用いた。

教師データの作成
----------------

ニューラルネットワークポテンシャル作成に必要な教師データはPHASE/0コード[6]による第一原理分子動力学シミュレーションの軌跡より得た。

第一原理分子動力学シミュレーションの計算条件
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

第一原理分子動力学シミュレーションは以下の条件で行った。

==================== ============================================
計算条件                 設定値
==================== ============================================
カットオフエネルギー           25 Rydberg
*k*\ 点サンプリング  cubic系： $2 \\times 2 \\times 1$

                     アモルファス，液体： $\\Gamma$ 点のみ
収束判定条件               1e-8 hartree/atom
時間刻み                 4 fs
アンサンブル               NVTアンサンブル
==================== ============================================

cubic Ge\ :sub:`2`\ Sb\ :sub:`4`\ Te\ :sub:`5`\ の第一原理分子動力学シミュレーション
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

GeSbTe系の典型例としてGe\ :sub:`2`\ Sb\ :sub:`4`\ Te\ :sub:`5`\ があげられる。Ge\ :sub:`2`\ Sb\ :sub:`4`\ Te\ :sub:`5`\ は結晶としては立方晶系と六方晶系があり，六方晶の方がエネルギー的には安定であると言われている。他方アモルファス相とのスイッチングに使いやすいのはエネルギー的には近いであろう立方晶の方ではないかと考えられる。そこで，ここでは結晶の教師データとして立方晶のGe\ :sub:`2`\ Sb\ :sub:`4`\ Te\ :sub:`5`\ を用いることにした。

立方晶Ge\ :sub:`2`\ Sb\ :sub:`4`\ Te\ :sub:`5`\ は，面心立方格子の<111>方向に原子がTe/SbないしGeないし空孔/Te/SbないしGeないし空孔/…
という具合にスタックした構造である。その典型例は次に示すような構造である。

|image0|

図1 Ge\ :sub:`2`\ Sb\ :sub:`4`\ Te\ :sub:`5`\ の結晶構造の例

上図において緑色で描画されている球がGe, 紫色で描画されている球がSb, 橙色で描画されている球がTeである。
Ge:Sb:Teを2:2:5という比率で成立させるため細長い単位胞となっている。
Teの位置は固定であるのに対し，GeとSbは空孔を含めランダムになっている。
そこで，Ge/Sb/空孔位置をランダムに埋めた構造を20通り用意し，分子動力学シミュレーションの初期原子配置とした。
温度は500Kと1500 Kを採用し，各々1万ステップの\ *NVT*\ 第一原理分子動力学シミュレーションを実行した。

液体Ge\ :sub:`2`\ Sb\ :sub:`2`\ Te\ :sub:`5`\ の第一原理分子動力学シミュレーション
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

立方体の単位胞に10
fu分の原子をランダムに敷き詰めた構造を初期構造とした。温度3000Kで\ *NVT*\ 第一原理分子動力学シミュレーションを行った。Ge\ :sub:`2`\ Sb\ :sub:`2`\ Te\ :sub:`5`\ の融点は900K程度なので非常に高温のシミュレーションであるが，多様な構造のサンプリングを狙いこの温度を採用した。Ge格子定数を二種類用意し，それぞれに対して4万ステップ程度のシミュレーションを行った。

メルトクエンチシミュレーション
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

上述の液体のシミュレーションから20通りの初期配置をサンプルし，急冷のシミュレーションを実施した。温度3000Kから300Kまで3万ステップかけて冷却した。アンサンブルは\ *NVT*\ を採用した。

教師データサンプリング
~~~~~~~~~~~~~~~~~~~~~~

第一原理分子動力学シミュレーションのステップ間のデータは相関が強く，毎ステップサンプルして教師データとするとデータ数に対して十分多様なデータが得られない可能性が高い。そこで，得られた軌跡から25ステップに一度サンプルすることによって最終的な教師データとした。データ点数は合計で43,000ほどとなった。

GeSb\ :sub:`2`\ Te\ :sub:`4`\ の教師データ追加
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

後述の手続きで作成したNNPを用いてGeSb\ :sub:`2`\ Te\ :sub:`4`\ の急冷シミュレーションを実施し，教師データに追加した。合計で4000点ほど追加した。

n2p2コードを用いたニューラルネットワークポテンシャルの作成
----------------------------------------------------------

ニューラルネットワークポテンシャルはn2p2コード[5]を用いて作成した。Symmetry
functionは文献[4]の方針に従い定義した。二体のsymmetry
functionは元素の組み合わせあたり5通りで計45通り，三体のsymmetry
functionは元素の組み合わせあたり20通りで計360通り用意した。カットオフ距離は6
Åとした。Activation functionとしては隠れ層に対してはhyperbolic
tangentを，出力層に対しては線形の関数を採用した。ニューラルネットワークとしては隠れ層二層，各層あたり20ノードとした。エネルギーだけでなく原子間力も学習に用いる設定を採用した。教師データの9割を学習に，1割をテストに用いた。そのほか学習の仕方の詳細などについてはn2p2のデフォルト設定を採用した。
結果得られたニューラルネットワークポテンシャルを用いて作成したparity plotを次に示す。

|image1|

図2 得られたニューラルネットワークポテンシャルのparity plot.

得られたニューラルネットワークポテンシャルは，学習に用いたデータに対してもテストデータに対してもおおよそroot
mean square errorがエネルギーに対して6 meV/atom，原子間力に対して0.22 eV/Åの精度で教師データを再現することができた。
ニューラルネットワークポテンシャルは問題によってはエネルギーに対して1
meV/atom以下の精度を得ることもできる場合があるが，ここで得られた精度は第一原理計算そのものの精度と比較できるオーダーであり，実用上十分であると考えている。

ニューラルネットワークポテンシャルの使い方
==========================================

ポテンシャルファイル
--------------------

ポテンシャルファイルはn2p2ディレクトリー以下に配置されている。以下のファイルが存在する。

- input.nn
- scaling.data
- weights.032.data
- weights.051.data
- weights.052.data

input.nnファイルにはNNPに用いられているニューラルネットワークに関する情報などが記録されている。scaling.dataファイルにはsymmetry
functionのスケーリングに関する情報が記録されている。weights.032.data,
weights.051.data, weights.052.dataファイルにはそれぞれGe, Sb,
Teのニューラルネットワークの重みが記録されている。このディレクトリーをインプットスクリプトにおいて指定することによって利用することができる。

プログラムのコンパイル方法
--------------------------

n2p2をインストールする方法
~~~~~~~~~~~~~~~~~~~~~~~~~~

n2p2をインストールする方法について説明する。Linux環境
(WSL上のLinuxでも可)を想定しているが，macOSにも似た手続きによってインストールできるかもしれない。

必要なライブラリーのインストール
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

n2p2は
GSL (https://www.gnu.org/software/gsl/) と
Eigen (https://eigen.tuxfamily.org/)
を必要とする。利用したい環境にこれらがインストールされていない場合上述のウェブサイトからアーカイブをダウンロードする。バージョンにそれほど依存しないはずなので，最新版をダウンロードすればよい。

また，BLAS
(https://www.netlib.org/blas/) も必要である。BLASはすでにインストールされている場合も多いと思われるが，インストールされていない場合は何らかのBLASの実装を入手し，インストールする。

GSLはコンパイルする必要がある。通常のGNU/Linuxアプリケーションの手続きによってコンパイルすることができる。すなわち

::

  ./configure
  make
  sudo make install

のような手続きである。管理者権限のないアカウントで作業をする場合は./configureのあとに--prefix=INSTALL_DIRECTORYをつけることによって書き込み権限のあるディレクトリーをインストールするディレクトリーとして指定する。この場合環境変数LD_LIBRARY_PATHにINSTALL_DIRECTORY/libを加える必要がある。

Eigenはテンプレートライブラリーなのでコンパイルする必要はないが，解凍後得られるトップディレクトリーの下にあるINSTALLファイルに記述されている方法でインストールしておくことを推奨する。

n2p2のコンパイル
^^^^^^^^^^^^^^^^

n2p2のアーカイブを配布元
(https://github.com/CompPhysVienna/n2p2/releases)
からダウンロードし，展開する。バージョンは分子動力学シミュレーターLAMMPS
(https://www.lammps.org/) に正式に取り入れられた2.14以降を用いる。

ソースコードはsrcディレクトリー以下に配置されている。srcディレクトリーに配置されているファイルやディレクトリーは下記の通り。

- application/
- doc/
- interface/
- libnnp/
- libnnpif/
- libnnptrain/
- makefile
- makefile.gnu
- makefile.intel
- makefile.llvm
- pynnp/

makefile.gnuはgcc用の設定が記述されたファイル，makefile.intelにはIntel oneAPI用の設定が記述されたファイル，makefile.llvmはclangコンパイラー用の設定が記述されたファイルである。
これらの内利用したいコンパイラーに対応したファイルをエディターなどで開き，以下の赤色で示した部分を編集する。

::

  PROJECT_GSL=/usr/local/include/gsl
  PROJECT_EIGEN=/usr/local/include/eigen3

PROJECT_GSLにはGSLのインクルードファイルのパスを指定する。
gslのインストール先がたとえば/home/user/gslだった場合この指定は/home/user/gsl/include/gsl となる。
PROJECT_EIGENにはEigenのインストールディレクトリーを指定する。
Eigenのインストール先がたとえば/home/user/eigen3だった場合この指定は/home/user/eigen3/include/eigen3となる。

この編集ができたら，たとえばmakefile.gnuを使う場合

::

  make COMP=gnu

というコマンドを実行するとn2p2のコンパイルが始まる。
問題が発生しなければNNPを作成するためのプログラムがbin以下に，LAMMPSなどとリンクするためのライブラリーがlib以下に生成される。

n2p2のNNPが利用できるLAMMPSをビルドする方法
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

LAMMPSのアーカイブを配布元 (https://www.lammps.org/) からダウンロードする。
バージョンはn2p2を正式に取り込んだ29 September 2021版以降を利用する。

まずはn2p2を取り込むための準備として，lib/hdnnpディレクトリーへ移り，そこに配置されているInstall.pyというPythonスクリプトを実行する。

::

  cd lib/hdnnp
  python Install.py –p /home/user/n2p2

ここでn2p2は/home/user/n2p2以下にインストールされていると仮定した。この操作によって

- Makefile.lammps
- includelink
- liblink

という三つのシンボリックリンクが生成されていればこの段は成功である。

つぎにsrcディレクトリーに移動し，n2p2のNNPを利用できるようにするパッケージml-hdnnpを有効にする。

::

  cd ../../src
  make yes-ml-hdnnp

ほかにも有効にしたいパッケージがあれば同様の手続きで有効化しておく。
さらに必要に応じてsrc/MAKEの下にあるMakefile.mpiもしくはMakefile.serialを編集する。
前者はmpi並列用のMakefile, 後者はシリアル実行用のMakefileである。
ここまで準備ができたらmakeコマンドによってLAMMPSをコンパイルすればよい。

::

  make mpi

もしくは

::

  make serial

問題が発生しなければsrcディレクトリーの下にlmp_mpi (MPI並列版の場合) もしくはlmp_serial (MPI非並列版の場合)が得られる。

LAMMPSの実行方法
----------------

インプットスクリプトの書き方
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

LAMMPSのインプットスクリプトはニューラルネットワークポテンシャル指定部分以外は通常の設定を採用すればよい。
作成したニューラルネットワークポテンシャルはエネルギーの単位としてはeV, 長さの単位としてはÅを採用しているので，units metalを利用し，初期原子配置作成の際も留意する（後述のようにスケーリングファクターによって調整することもできる）

インプットスクリプトのポテンシャル指定部分は以下のように記述する。

::

  pair_style hdnnp 6.0 dir ../n2p2 showew no showewsum 1000 resetew yes maxew 10000 cflength 1.0 cfenergy 1.0
  pair_coeff \* \* Ge Sb Te

一行目

-  pair_style hdnnpによってn2p2のNNPを使うことを指定している。
-  続く6.0によってカットオフが6.0 Åであることを指定している。6.0はNNP作成時に採用した値であり，これより短くしてはならない。
-  続くdir ../n2p2 によって一階層上のn2p2というディレクトリーにNNPのファイルが配置されていることを指定している。この部分は計算の実行ディレクトリーの位置によって変わりえる。相対パスではなく絶対パスを用いて指定してもよい。
-  続くshowew no とすることによってerror warningを出力しないという設定を行っている。
-  続くshowewsum 1000によって1000ステップに一度積算エラーを出力するように設定している。
-  続くresetew yesによってerror warningは出力する度にリセットすることを設定している。
-  続くmaxew 10000によってerror warningが10000を超えた場合に計算を終了させることを設定している。
-  続くcflength 1.0によって長さに関するスケーリングファクターを1.0にしている。用いるunitsがmetalの場合の設定であり，別のunitsを用いる場合は相応の値を採用する。
-  続くcfenergy 1.0によってエネルギーに関するスケーリングファクターを1.0にしている。用いるunitsがmetalの場合の設定であり，別のunitsを用いる場合は相応の値を採用する。

二行目

pair_coeffコマンドによって一番目の元素がGe, 二番目の元素がSb, 三番目の元素がTeに対応することを設定している。

計算実行
~~~~~~~~

通常通りLAMMPSを起動すればよい。たとえば以下のようなコマンドを実行する。

::

  mpiexec -n N ~/lammps-2Aug2023/src/lmp_mpi -in in

NはMPI並列数である。利用しているコンピューターのコア数を超えない数値を指定する。

ログファイル
~~~~~~~~~~~~

ヘッダー部分では，通常のLAMMPSの計算のログに加え，用いているニューラルネットワークポテンシャルの様々な情報が出力される。

MD計算中は上述のshowewsumの設定に応じてエラーの積算値が出力される。

::

  ### NNP EW SUMMARY ### TS: 1000 EW 203 EWPERSTEP 2.030e-01

1000ステップに一度エラーの積算値が出力されており，総計203回，1 MDステップあたり2.03e-01回エラーが発生したことが分かる。
この例では初期配置として教師データに含まれない構造を採用したのでエラーが発生してしまったが，以降シミュレーションが進行するに従いエラーは減っていく傾向だった。

エラーは原子配置が教師データに対して外挿となる領域に至った場合に報告される。
このエラーが発生したからといって即座に計算を棄却しなければならないとは限らないものの壊滅的な結果が得られてしまう場合もあるので，エラー発生時はその後の結果をよく吟味することが推奨される。

計算例
======

急冷のシミュレーションによってあらかじめ作成しておいたアモルファス構造を初期配置とし，複数の温度で分子動力学シミュレーションを行った。

計算条件
--------

分子動力学シミュレーションの主な計算条件は下記の通り。

============ =============================
計算条件     設定値
============ =============================
時間刻み     4 fs
カットオフ長 6 Å
アンサンブル *NPT*\ アンサンブル
温度         100Kから1000Kまで，100Kきざみ
ステップ数   1000000
============ =============================

初期原子配置としてはすべての温度で同じものを利用した。まずは第一原理計算メルトクエンチシミュレーションによって得たアモルファス構造の $2 \\times 2 \\times 2$ スーパーセルを作成し，1000Kから300Kまで急冷のシミュレーションを実施した。得られた最後のスナップショットを初期原子配置とした。その構造を図3に示す。

|image2|

図3 初期原子配置

計算結果
--------

得られた結果を紹介する。図4と図5はそれぞれ300K, 600K,
900KにおけるGe\ :sub:`2`\ Sb\ :sub:`2`\ Te\ :sub:`5`\ とGeSb\ :sub:`2`\ Te\ :sub:`4`\ のスナップショットである。いずれの場合も300Kにおいてはアモルファス構造が維持されているのに対し600Kでは構造が大きく変わり，周期的な構造が得られている。900Kの場合は周期構造は維持できず，液体構造が得られている。

|image3|

図4
Ge\ :sub:`2`\ Sb\ :sub:`2`\ Te\ :sub:`5`\ の分子動力学シミュレーションにおいて得られた原子配置のスナップショット

|image4|

図5
GeSb\ :sub:`2`\ Te\ :sub:`4`\ の分子動力学シミュレーションにおいて得られた原子配置のスナップショット

より定量的に判断するため，図6に温度と平均エネルギーの関係をプロットする。エネルギーは後半500000ステップのエネルギーを平均することによって求めた。通常温度を上げるとそれに伴い系のポテンシャルエネルギーも上昇する。しかしながら今の場合400-500Kあたりにおいていったんエネルギーが下がる傾向がみられる。これはアモルファス構造が周期的な構造に転移したためである。さらに温度が上昇し，800Kになると液体に転移するためエネルギーは大幅に上昇する。

|image5|

図6 温度とエネルギーの関係

図7には結晶化前後における時間とエネルギーの関係を示す。
1.35 ns以降急激にエネルギーが下がり，1.4 nsからは一定値に振動するような振る舞いになっている。
このことは結晶化しはじめてから100 psかからず全系が結晶化したことをあらわしている。

|image6|

図7 結晶化前後のエネルギーの履歴

最後に，アモルファス構造から結晶に転移する様子の動画を紹介したい。
この動画はGe\ :sub:`2`\ Sb\ :sub:`2`\ Te\ :sub:`5`\ の600Kのシミュレーションから得られた軌跡から作成したものである。
コマ間の間隔は実時間では0.1 s, シミュレーション時間では40 psである。
開始数秒で結晶化の兆しが見え始め，その後非常に短い時間で結晶に転移している様子がわかる。

|movie1|

図8 アモルファス構造から結晶に転移する様子。

補遺
========

ニューラルネットワークポテンシャルの作り方
--------------------------------------------

本リポジトリでは第一原理バンド計算ソフトウェアPHASE/0を用いて作成した教師データとニューラルネットワークポテンシャル作成ソフトウェアn2p2用の入力ファイルを公開している。ここではこれらのファイルを用いてニューラルネットワークポテンシャルを作成する具体的な手続きを紹介する。


教師データファイル
~~~~~~~~~~~~~~~~~~~~

教師データファイルのファイル名はinput.dataである。リポジトリの `training_data <https://github.com/atomic-scale/NNP-GST/tree/main/training_data>`_ 以下に配置されている。ファイルサイズの関係で分割して保存されているので，以下の要領で結合して利用する。

::

  cat xa? | xz -d > input.data


おおよそ771MB程度の大きさのファイルが得られる。その内容を抜粋する。

::

   begin
  comment phase0_1500_0
  lattice         8.516892992400864        -0.025242363548024        -0.000694876561710
  lattice         4.236533604743143         7.413961973164201        -0.001139519543545
  lattice        -0.096170146547667        -0.234410814552019        54.370394528364578
  atom        -0.222759166010661         0.084208040563042         0.299883377989237 Ge    0.0 0.0         0.299739319401635        -0.322056503244542        -0.277062180980615
  atom         6.312908761141252         1.584407379396599         3.783418586980273 Ge    0.0 0.0         0.133080349736049        -0.624624037188481        -0.021237320108574
  atom         1.811583586837962         1.180068902721112         3.914461900153025 Ge    0.0 0.0         0.060935167866004        -0.070088298566551        -0.243380716885904
  ...
  ...
  energy    -68792.976955941441702
  charge 0.0
  end

一つの原子配置のデータを ``begin`` と ``end`` の間に記述する。すなわち，以下のコマンドによって原子配置がいくつ定義された教師データファイルなのかを調べることができる。

::

 $ grep begin input.data | wc -l
 47428

``begin`` に続く行はコメント行である。何を記録してもよいが，その原子配置の素性が分かるような文字列を利用することが望ましい。``lattice`` から始まる三行に格子ベクトルをÅ単位で記録する。一つ一つの原子は ``atom`` から始まる行で記録する。スペース区切りで次のように9つのデータを記述する。

::

  x座標 y座標 z座標 元素名 電荷(未使用） n (詳細不明，未使用) 原子間力のx座標 原子間力のy座標 原子間力のz座標

長さの単位はÅ, 原子間力の単位はeV/Åである。エネルギーは ``energy`` の後にeV単位で記録する。最後に系の総電荷を ``charge`` のあとに記録することができる。

n2p2の入力ファイル
~~~~~~~~~~~~~~~~~~~~

n2p2の入力ファイルのファイル名は ``input.nn`` である。リポジトリの `n2p2 <https://github.com/atomic-scale/NNP-GST/tree/main/n2p2>`_ の下に配置されている。主要部分を抜粋する。

::

  ###############################################################################
  # DATA SET NORMALIZATION
  ###############################################################################
  mean_energy  -2.5528578277780052E+00 # nnp-norm
  conv_energy   6.8819868611177233E+00 # nnp-norm
  conv_length   4.7939149349223875E+00 # nnp-norm
  ###############################################################################

  ###############################################################################
  # GENERAL NNP SETTINGS
  ###############################################################################
  # These keywords are (almost) always required.
  number_of_elements             3             # Number of elements.
  elements                        Ge Sb Te     # Specification of elements.
  atom_energy                     Ge -103.43071732189050 # Free atom reference energy
  atom_energy                     Sb -2191.81887945960460 # Free atom reference energy
  atom_energy                     Te -223.5391948990360 # Free atom reference energy
  cutoff_type                     2              # Cutoff type (optional argument: shift parameter alpha).
  scale_symmetry_functions                       # Scale all symmetry functions with min/max values.
  #scale_symmetry_functions_sigma                 # Scale all symmetry functions with sigma.
  scale_min_short                 0.0            # Minimum value for scaling.
  scale_max_short                 1.0            # Maximum value for scaling.
  center_symmetry_functions                      # Center all symmetry functions, i.e. subtract mean value.
  global_hidden_layers_short      2              # Number of hidden layers.
  global_nodes_short              20 20             # Number of nodes in each hidden layer.
  global_activation_short         t t l          # Activation function for each hidden layer and output layer.
  #normalize_nodes                                # Normalize input of nodes.
  ...
  ...
  ...
  #
  ###############################################################################
  # ADDITIONAL SETTINGS FOR DATASET TOOLS
  ###############################################################################
  # These keywords are used only by some tools handling data sets:
  # nnp-comp2, nnp-scaling, nnp-dataset, nnp-train.
  use_short_forces                               # Use forces.
  random_seed                     1234567        # Random number generator seed.

  ###############################################################################
  # ADDITIONAL SETTINGS FOR TRAINING
  ###############################################################################
  # These keywords are solely used for training with nnp-train.
  epochs                          200            # Number of training epochs.
  ...
  ...
  test_fraction                   0.1            # Fraction of structures kept for testing.
  force_weight                    10.0           # Weight of force updates relative to energy updates.
  short_energy_fraction           1.000          # Fraction of energy updates per epoch.
  short_force_fraction            0.0041         # Fraction of force updates per epoch.
  ...
  ...
  write_trainpoints               100           # Write energy comparison every this many epochs.
  write_trainforces               100              # Write force comparison every this many epochs.
  write_weights_epoch             1              # Write weights every this many epochs.
  write_neuronstats               100              # Write neuron statistics every this many epochs.
  write_trainlog                                 # Write training log file.
  ...
  ...
  ...
  symfunction_short Ge 2 Ge 3.951E-01 1.500E+00 6.000E+00
  symfunction_short Ge 2 Ge 3.951E-01 2.625E+00 6.000E+00
  ...
  ...
  ...
  symfunction_short Ge 3 Ge Ge 3.951E-01 -1 1.000E+00 6.000E+00 1.500E+00
  symfunction_short Ge 3 Ge Ge 3.951E-01  1 1.000E+00 6.000E+00 1.500E+00
  ...
  ...
  ...

``#`` から始まる行はコメント扱いとなる。基本的には ``keyword value`` という形式で設定を施すが，symmetry functionの設定は複雑なこともありこの限りではない。

``input.nn`` ファイルの先頭には ``mean_energy`` ``conv_energy`` ``conv_length`` というキーワードの設定値があり，これらは教師データの規格化因子である。``input.data`` のデータから手動で計算してもよいが後に説明する ``nnp-norm`` プログラムによってプログラムに決めさせることが推奨である。

``number_of_elements`` に元素数を指定し， ``elements`` に元素名を指定する。``atom_energy`` には元素の単体原子のエネルギーを指定する。原子のエネルギーはエネルギーの原点を変更するに過ぎないので0にしてもよいが，教師データに化学量論比の異なるデータが含まれる場合は原点がきっちりと定まっていた方がよい学習ができる場合がある。

``global_hidden_layers_short`` にはニューラルネットワークの隠れ層の数を指定し，さらに ``global_nodes_short`` において各隠れ層の層数を指定する。``global_activation_short`` には各層において用いるacitvation functionを指定する。最初の2つの文字列が隠れ層に対応する。3番目の，最後の指定が出力層に対応する。この例の場合隠れ層2層は ``t`` すなわちhyperbolic tangent関数が，出力層は ``l`` すなわち線形の関数が利用される指定となる。

``use_short_forces`` を指定するとエネルギーだけでなく原子間力を用いた学習を行う。このオプションを有効にするとより精度の高い学習が行われることが期待できるが，メモリ要求が飛躍的に増加する。たとえば本リポジトリの ``input.data`` ファイルの場合 ``use_short_forces`` を有効にすると学習時に約230 GBのメモリが必要であった。このオプションを用いて大きな教師データを用いた学習を行う場合，十分なノード数を確保できる分散並列環境は必須である。

``epochs`` には学習の上限回数を指定する。ここでは200としているが，n2p2による学習は多くの場合数十epochでそれ以上学習してもあまり改善しない状態になる。各epochのポテンシャルファイル自体は履歴が残るようになっているので，あとからログを見返して最もよさそうなepochのポテンシャルファイルを利用するようにすればよい。

``test_fraction`` には教師データのうちテストにまわす割り合いを指定する。この例では0.1としている。

``write_trainpoints`` ``write_trainforces`` には原子間力を何epochに一回出力するかを指定する。頻繁に出力するとファイル数が膨大になるので，この例では100とし，ある程度抑制する設定を施している。``write_weights_epoch`` には何epochに一回ニューラルネットワークの重みデータを出力するかを指定する。こちらは最もよいepochをあとから見出して採用するファイルを決めたいので，毎epoch出力する1という値を指定している。

``symfunction_short`` によって利用したいsymmetry functionを定義する。 ``symfunction_short`` 以降スペース区切りでそのsymmetry functionの設定を行う。1つ目の設定は対応する元素，2つ目の設定はsymmetry functionの種類を表す整数値である。3つ目以降はsymmetry functionの種類に応じて変化する部分である。Symmetry functionの種類が2というのは $G^2_i$ に対応する。相手の元素 $\\eta_2$ $r_s$ カットオフ長 の順にスペース区切りで設定を施す。Symmetry functionの種類が3というのは $G^3_i$ に対応する。相手の元素1 相手の元素2 $\\eta_3$ $\\lambda$ $\\zeta$ カットオフ長 $r_s$ の順にスペース区切りで設定を施す。Symmetry functionをいくつ定義するか，また各symmetry functionのパラメーターをどのように選べばよいかについての指針は，たとえば文献[3],[4]などにおいて提案されている。本リポジトリの ``input.nn`` ファイルは文献[4]の指針に従って決めている。その際， `sfparamgen.pyスクリプト <https://e-cam.readthedocs.io/en/latest/Classical-MD-Modules/modules/n2p2/n2p2_symfunc_param_generator/readme.html>`_ を用いると比較的簡単に設定することができる。

ポテンシャルファイル作成
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

以降n2p2のインストールは上述の方法によって終了しているものとして説明を行う。また，n2p2は ``$HOME/n2p2`` 以下にインストールされていることを想定する。

教師データの規格化因子の計算
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

教師データの規格化因子を計算する。この処理は ``input.nn`` ファイルに ``mean_energy`` ``conv_energy`` ``conv_length`` の設定がすでに施されている場合行う必要がない（設定が施された状態で ``nnp-norm`` を実行するとエラーが得られる）作業ディレクトリーに ``input.nn`` ファイルと ``input.data`` ファイルを配置し，以下のコマンドを実行すればよい。

::

  $HOME/n2p2/bin/nnp-norm

この処理はたとえ巨大な教師データファイルを用いたとしてもすぐに終了するので，非並列で実行している。このプログラムは規格化因子を計算し，その結果を ``input.nn`` ファイルに記録する。 ``input.nn`` ファイルの先頭を確認し，``mean_energy`` ``conv_energy`` ``conv_length`` の設定が記録されていればこの段は終了である。

座標データの記述子への変換
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

教師データを記述子に変換する。以下のコマンドを実行すればよい。

::

  mpirun -n N $HOME/n2p2/bin/nnp-scaling 100

このコマンドは ``nnp-norm`` よりは時間がかかるため， ``mpirun`` を介して実行することによってMPI並列実行を行っている。コマンド中の ``N`` はMPI並列数である。所要時間は教師データサイズの大きさや並列数に依存する。このコマンドによってsymmetry functionの変換が行われるが，この際symmetry functionの分布のヒストグラムが出力される。ヒストグラム出力の分割数を引数に与える（上述の例では100）

``nnp-scaling`` を実行すると以下のようなファイル群が得られる。

================================ ==================================================================
ファイル名                       説明
================================ ==================================================================
function.data                    symmetry functionの情報が記録されるファイル
nnp-scaling.log.xxxx             nnp-scalingのログファイル。xxxxはMPIのプロセス番号
scaling.data                     symmetry functionのスケーリングに関する情報が記録されている\
                                 ファイル。訓練時やポテンシャル利用時にも必要となる重要なファイル。
sf.xxx.yyy.histo                 ヒストグラムが記録されたファイル。xxxは原子番号，yyyは\
                                 symmetry functionの識別番号。
================================ ==================================================================

``nnp-scaling.log.xxxx`` ファイルには，以下のように使用メモリの情報が記録される。

::

  *** MEMORY USAGE ESTIMATION ***************************************************

  Estimated memory usage for training (keyword "memorize_symfunc_results":
  Valid for training of energies and forces.
  Memory for local structures  :        19426660 bytes (18.53 MiB = 0.02 GiB).
  Memory for all structures    :       108669504 bytes (103.64 MiB = 0.10 GiB).
  Average memory per structure :         5433475 bytes (5.18 MiB).
  *******************************************************************************

ニューラルネットワークの学習
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

``nnp-norm`` ``nnp-scaling`` を実行すると必要なデータがそろうので， ``nnp-train`` によって学習を行う。必要に応じて ``input.nn`` ファイルを編集し，以下のようなコマンドによって学習を行う。

::

  mpirun -n N $HOME/n2p2/bin/nnp-train

``nnp-scaling`` の場合と同様MPI並列で実行する例である。``nnp-train`` は特に引数はない。実行時間は教師データの数や並列数に大きく依存するが， ``nnp-scaling`` よりははるかに多くの時間がかかると考えられる。

``nnp-train`` を実行すると以下のようなファイル群が得られる。

================================ ==================================================================
ファイル名                       説明
================================ ==================================================================
learning-curve.out               Epochごとのエネルギーや原子間力のMAE, RMSEなどが記録されている\
                                 ファイル。
neuron-stats.xxxx.out            ニューロン情報が記録されているファイル。xxxxはepoch番号
nnp-train.log.xxxx               ``nnp-train`` のログファイル。xxxxはMPIプロセス番号
test.data                        教師データのうちテストに回したデータ
testforces.xxxx.out              テストデータの原子間力が記録されているファイル。xxxxはepoch番号
testpoints.xxxx.out              テストデータのエネルギーが記録されているファイル。xxxxはepoch番号
timing.out                       経過時間が記録されているファイル。
train-log.out                    nnp-train.log.xxxxファイルとは異なる情報が記録されたログファイル
train.data                       教師データのうち訓練に用いるデータ
trainforces.xxxx.out             訓練データの原子間力が記録されているファイル。xxxxはepoch番号
trainpoints.xxxx.out             訓練データのエネルギーが記録されているファイル。xxxxはepoch番号
updater.000.out                  学習過程の詳細が記録されているファイル。
weights.xxx.yyyy.out             ニューラルネットワークの重み係数が記録されているファイル。\
                                 ポテンシャル使用の際に必要となるファイル。xxxは原子番号，\
                                 yyyyはepoch番号である。
================================ ==================================================================

``learning-curve.out`` ファイルには学習の差異の訓練データおよびテストデータとの誤差が記録される。たとえば以下のような内容になる。

::

  ################################################################################
  # Learning curves for energies and forces.
  ################################################################################
  # Col  Name             Description
  ################################################################################
  # 1    epoch            Current epoch.
  # 2    RMSEpa_Etrain_pu RMSE of training energies per atom (physical units)
  # 3    RMSEpa_Etest_pu  RMSE of test energies per atom (physical units)
  # 4    RMSE_Etrain_pu   RMSE of training energies (physical units)
  # 5    RMSE_Etest_pu    RMSE of test energies (physical units)
  # 6    MAEpa_Etrain_pu  MAE of training energies per atom (physical units)
  # 7    MAEpa_Etest_pu   MAE of test energies per atom (physical units)
  # 8    MAE_Etrain_pu    MAE of training energies (physical units)
  # 9    MAE_Etest_pu     MAE of test energies (physical units)
  # 10   RMSE_Ftrain_pu   RMSE of training forces (physical units)
  # 11   RMSE_Ftest_pu    RMSE of test forces (physical units)
  # 12   MAE_Ftrain_pu    MAE of training forces (physical units)
  # 13   MAE_Ftest_pu     MAE of test forces (physical units)
  # 14   RMSEpa_Etrain_iu RMSE of training energies per atom (training units)
  # 15   RMSEpa_Etest_iu  RMSE of test energies per atom (training units)
  # 16   RMSE_Etrain_iu   RMSE of training energies (training units)
  # 17   RMSE_Etest_iu    RMSE of test energies (training units)
  # 18   MAEpa_Etrain_iu  MAE of training energies per atom (training units)
  # 19   MAEpa_Etest_iu   MAE of test energies per atom (training units)
  # 20   MAE_Etrain_iu    MAE of training energies (training units)
  # 21   MAE_Etest_iu     MAE of test energies (training units)
  # 22   RMSE_Ftrain_iu   RMSE of training forces (training units)
  # 23   RMSE_Ftest_iu    RMSE of test forces (training units)
  # 24   MAE_Ftrain_iu    MAE of training forces (training units)
  # 25   MAE_Ftest_iu     MAE of test forces (training units)
  ##################################################################################################################################################################################################################################################################################################################################################################################################################################
  #        1                2                3                4                5                6                7                8                9               10               11               12               13               14               15               16               17               18               19               20               21               22
        23               24               25
  #    epoch RMSEpa_Etrain_pu  RMSEpa_Etest_pu   RMSE_Etrain_pu    RMSE_Etest_pu  MAEpa_Etrain_pu   MAEpa_Etest_pu    MAE_Etrain_pu     MAE_Etest_pu   RMSE_Ftrain_pu    RMSE_Ftest_pu    MAE_Ftrain_pu     MAE_Ftest_pu RMSEpa_Etrain_iu  RMSEpa_Etest_iu   RMSE_Etrain_iu    RMSE_Etest_iu  MAEpa_Etrain_iu   MAEpa_Etest_iu    MAE_Etrain_iu     MAE_Etest_iu   RMSE_Ftrain_iu    RMSE_Ftest_iu    MAE_Ftrain_iu     MAE_Ftest_iu
  ##################################################################################################################################################################################################################################################################################################################################################################################################################################
             0   1.35549798E-03   5.76728147E-04   2.00248431E-01   3.53961709E-02   1.17549549E-03   4.75449108E-04   1.40966961E-01   2.91890733E-02   2.75526589E-02   1.94204702E-02   1.83888104E-02   1.50295473E-02   1.15444435E+00   4.91185202E-01   1.70546672E+02   3.01460497E+01   1.00114064E+00   4.04928331E-01   1.20058100E+02   2.48596170E+01   1.02928276E+00   7.25489151E-01   6.86949507E-01   5.61457751E-01
             1   2.00593579E-03   1.73507278E-03   3.42678216E-01   1.52523426E-01   1.58986626E-03   1.44167622E-03   2.23821829E-01   1.06086833E-01   2.57738072E-02   2.00746032E-02   1.71130140E-02   1.46422170E-02   1.70840626E+00   1.47771889E+00   2.91850622E+02   1.29900457E+02   1.35405006E+00   1.22784024E+00   1.90623556E+02   9.03515506E+01   9.62830320E-01   7.49925550E-01   6.39289669E-01   5.46988280E-01
             2   5.87739903E-04   5.83183998E-04   7.29433297E-02   3.72266554E-02   4.82042388E-04   5.10077063E-04   4.92760252E-02   3.15678670E-02   2.71801537E-02   2.24067314E-02   1.78866331E-02   1.65356277E-02   5.00563645E-01   4.96683492E-01   6.21240429E+01   3.17050284E+01   4.10543666E-01   4.34420111E-01   4.19671808E+01   2.68855773E+01   1.01536711E+00   8.37046701E-01   6.68189707E-01   6.17720292E-01
    
1行が1 epochの誤差の記録となる。1行あたり多くの列が出力されるが，ヘッダー部分に各列の意味合いが記述されている。記録される誤差はmean-average errorもしくはroot mean square errorであり，原子間力かエネルギーか，訓練データかテストデータか，プログラム内部の単位か実単位か，などの組み合わせになっている。基本的にはテストデータに対応する列の数値が小さいほどよい。特に気を付ける必要があるのは訓練データの誤差は小さくなっているにも関わらずテストデータの誤差が大きくなっているような状況で，これはいわゆる過学習状態に陥ってしまっている蓋然性が高い。

ファイルコピー（リネーム）
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  
``nnp-train`` が出力するファイルのファイル名は ``weights.xxx.yyyy.out`` であるが，実際に利用する際には ``weights.xxx.data`` というファイル名にする必要がある。学習の履歴を確認して採用するepochを決めたらファイルをコピーもしくはリネームする。

::
  
  cp  weights.xxx.yyyy.out weights.xxx.data

``weigts.xxx.data`` ファイル， ``input.nn`` ファイル， ``scaling.data`` ファイルがニューラルネットワークポテンシャルを利用するために必要なファイル群なので，これらのファイルを一つのディレクトリーにまとめておいておく。

作ったニューラルネットワークポテンシャルの使い方
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
LAMMPSからニューラルネットワークポテンシャルを利用する方法は上述した通り。ここではn2p2に含まれる ``nnp-predict`` を用いてエネルギーや原子間力の計算を行う方法を紹介する。通常LAMMPSを用いればそれで事足りるが， ``nnp-predict`` を利用すると教師データとの差分が計算されたり原子ごとのエネルギーを求めることができたりするため，有用な場合もある。

ポテンシャルファイル群を一つのディレクトリーに配置し，さらに対象としたい原子座標データを同じディレクトリーの ``input.data`` ファイルに記述する。``input.data`` ファイルの形式は教師データのそれと同じであるが，複数の原子配置が記録されていたとしても最初の一つのみが計算対象となる。

準備ができたら以下の要領で ``nnp-predict`` を実行する。

::

  mpirun -n N $HOME/n2p2/bin/nnp-predict 0

引数にはデバッグ用の情報を ``structure.out`` に出力するかどうかを指定する。0を指定するとデバッグ情報は出力されず，1を指定すると出力される。以下のようなファイル群が得られる。

================================ ==================================================================
ファイル名                       説明
================================ ==================================================================
energy.out                       エネルギーが記録されるファイル。``input.data`` 
                                 ファイルに記録されているエネルギーの値との差分も記録される。
nnatoms.out                      原子ごとのエネルギーが記録されるファイル。
nnforces.out                     原子間力が記録されるファイル。``input.data`` ファイル\
                                 に記録されている原子間力との差分も記録される。
output.data                      ``input.data`` ファイルのエネルギーや原子間力が\
                                 ニューラルネットワークのそれに置き換わったファイル
structure.out                    実行時に引数に1を渡した場合にデバッグ情報が記録されるファイル
nnp-predict.log                  ログファイル。エネルギーや原子間力の計算結果はこのファイルからも\
                                 参照することができる。
================================ ==================================================================

``energy.out`` ファイルには以下の要領でエネルギーが記録される。

::

  ################################################################################
  # Energy comparison.
  ################################################################################
  # Col  Name     Description
  ################################################################################
  # 1    Ennp     Potential energy predicted by NNP.
  # 2    Eref     Reference potential energy.
  # 3    Ediff    Difference between reference and NNP prediction.
  # 4    E_offset Sum of atomic offset energies (included in column Ennp).
  ################################################################################
  #              1                2                3                4
  #           Ennp             Eref            Ediff         E_offset
  ###################################################################
   -4.90037247E+03  -4.90037328E+03  -8.10829542E-04   0.00000000E+00

最後の行にエネルギーが記録される。ニューラルネットワークポテンシャルによるエネルギー， ``input.data`` ファイルに記録されているエネルギー，差分のエネルギー，エネルギーの原点の順にスペース区切りで記録される。単位はeVである。


``nnatoms.out`` ファイルには以下のように原子ごとのエネルギーが記録される。

::

  ################################################################################
  # Energy contributions calculated from NNP.
  ################################################################################
  # Col  Name      Description
  ################################################################################
  # 1    index     Atom index.
  # 2    e         Element of atom.
  # 3    charge    Atomic charge (not used).
  # 4    Ennp_atom Atomic energy contribution (physical units, no mean or offset energy added).
  ################################################################################
  #        1  2                3                4
  #    index  e           charge        Ennp_atom
  ###############################################
         0  O   0.00000000E+00   8.07375898E-03
         1  H   0.00000000E+00  -1.03774530E-02
         2  H   0.00000000E+00  -1.03988168E-02
         ...
         ...

``#`` から始まる行が終わったあとに各原子のエネルギーが記録される。原子のインデックス，元素名，電荷，エネルギーの順にスペース区切りで記録される。単位はやはりeVである。

``nnforces.out`` ファイルには以下のように原子間力が記録される。

::

  ################################################################################
  # Atomic force comparison (ordered by atom index).
  ################################################################################
  # Col  Name   Description
  ################################################################################
  # 1    fx     Force in x direction.
  # 2    fy     Force in y direction.
  # 3    fz     Force in z direction.
  # 4    fxRef  Reference force in x direction.
  # 5    fyRef  Reference force in y direction.
  # 6    fzRef  Reference force in z direction.
  # 7    fxDiff Difference between reference and NNP force in x dir.
  # 8    fyDiff Difference between reference and NNP force in y dir.
  # 9    fzDiff Difference between reference and NNP force in z dir.
  ########################################################################################################################################################
  #              1                2                3                4                5                6                7                8                9
  #             fx               fy               fz            fxRef            fyRef            fzRef           fxDiff           fyDiff           fzDiff
  ########################################################################################################################################################
   -5.52018089E-03  -2.55747558E-03  -2.72759232E-02  -6.53013700E-03  -2.85245900E-03  -2.79925540E-02  -1.00995611E-03  -2.94983421E-04  -7.16630767E-04
    4.45302177E-03  -5.87236582E-04   4.87879000E-03   4.51748800E-03  -5.17262000E-04   5.05257300E-03   6.44662297E-05   6.99745823E-05   1.73783000E-04
   -2.56188543E-04   2.44514067E-03   2.28215838E-02   9.58150000E-05   2.21126400E-03   2.34275760E-02   3.52003543E-04  -2.33876665E-04   6.05992181E-04
   -8.72809582E-04  -6.93552949E-03   2.70738301E-02  -2.31046000E-04  -7.15091400E-03   2.69447230E-02   6.41763582E-04  -2.15384511E-04  -1.29107106E-04
         ...
         ...

``#`` から始まる行が終わったあとに各原子の原子間力が記録される。計算結果のx, y, z座標 ``input.data`` ファイルに記録された原子間力のx, y, z座標，差分ベクトルのx, y, z座標の順に記録される。単位はeV/Åである。

ニューラルネットワークポテンシャル作成ソフトウェアについて
--------------------------------------------------------------------

本リポジトリにおいてはn2p2を用いてニューラルネットワークポテンシャルを作成したが，ニューラルネットワークポテンシャルを作成することのできるソフトウェアは他にも多く存在する。ここでは本稿の著者が利用した経験のあるニューラルネットワーク作成ソフトウェアについてその特徴や理論を紹介し，さらにn2p2も含めた各ソフトウェアの使い分けについて議論したい。

n2p2
~~~~~

概要
^^^^^

`n2p2 <https://compphysvienna.github.io/n2p2/>`_ はBehler-Parinello型のsymmetry functionを記述子として用いることのできるニューラルネットワークポテンシャル作成ソフトウェアである。GPL 3.0 Licenseのもと公開されている。

記述子
^^^^^^^^^

n2p2において用いることのできる記述子は `ウェブサイト <https://compphysvienna.github.io/n2p2/api/symmetry_function_types.html#_CPPv4N3nnp12SymFncExpRadE>`_ に記述がある。Behler-Parinello型のsymmetry function以外にもcompact supportを持つsymmetry functionなどを用いることができるようになっている。

ニューラルネットワーク
^^^^^^^^^^^^^^^^^^^^^^

学習先のニューラルネットワークはいわゆるfeedforward neural networkであり，その実装はライブラリーなどに頼ることなくn2p2内で行われている。利用可能なactivation functionは `ウェブサイト <https://compphysvienna.github.io/n2p2/api/neural_network.html#_CPPv4N3nnp13NeuralNetwork18ActivationFunction11AF_IDENTITYE>`_ から参照することができる。本リポジトリのインプットでも用いたhyperbolic tangent関数のほか，logistic関数 $\\frac{1}{1+e^{-x}}$  ，softplus関数 $\\ln\\left(1+e^x\\right)$ などを用いることができる。

LAMMPSとの連携
^^^^^^^^^^^^^^^^^^^^^^

上述したように，n2p2のライブラリーをビルドし，適切なリンクを作り，LAMMPSのソースディレクトリーにおいて ``make yes-ml-hdnnp;make mpi`` とすることによってn2p2のポテンシャルファイルを用いることができるLAMMPSバイナリーが得られる。

ænet
~~~~~

概要
^^^^^

`ænet <http://ann.atomistic.net/>`_ [7] はMozilla Public Licenseのもと公開されているニューラルネットワークポテンシャル作成ソフトウェアである。その特徴は，文献[7]において導入された"Chebishev descriptor"を記述子として用いることができる点にある(symmetry functionもサポートしている)。Behler-Parinello型のsymmetry functionを用いる場合，元素の組み合わせごとに複数のsymmetry functionを用意する必要がある。したがって，元素の数の二乗に比例する計算コストが発生する（三体の記述子の場合三乗）これに対しChebishev descriptorによる原子配置の表現では元素数に依存しない数で済むように設計されているため，元素数の多い系を扱うのに適した手法であると考えられる。

記述子
^^^^^^^^^

ænetにおいてはChebishev descriptorという独自の記述子を用いることができる。Chebishev descriptor においては，原子 $i$ の動径分布関数 (radial distribution function, RDF) と角度分布関数 (angular distribution function) をChebishev多項式 $\\left\\{ \\phi_{\\alpha} \\right\\}$ によって展開する。

$$ \\rm{RDF}_i \\left( r \\right) = \\sum_{\\alpha} c_{\\alpha}^\\left(2\\right) \\phi_{\\alpha} \\left( r \\right) $$

$$ \\rm{ADF}_i \\left( \\theta \\right) = \\sum_{\\alpha} c_{\\alpha}^\\left(3\\right) \\phi_{\\alpha} \\left( \\theta \\right) $$

このようにして展開する際の展開係数 $$c_{\\alpha}^\\left(2\\right)$$ および $$c_{\\alpha}^\\left(3\\right)$$ を原子配置をあらわす記述子として用いる。RDFとADFは元素ごとに計算するわけではないため，このままでは元素ごとの情報は記述子に含まれない。そこで，元素ごとに固有の重みパラメーターを導入し，その重みパラメーターを展開係数に乗したものを記述子に追加することを行う。以上の手続きによって得られる記述子の数は元素数に依存しない。元素ごとの重みパラメーターが具体的にどのように決まるかについては文献[7]には特に記述がなく，詳細は不明である。

元素の組み合わせごとに記述子を用意するわけではないため，その精度が問題になる可能性がある。文献[7]ではその点を検証し，Chebishev descritorによって到達できる限界のエネルギーのRMSEは元素数に関わらず3 meV/atom程度であることが報告されている。文献[7]の対応するグラフを見ると系によっては元素数が少ないほうが小さな次数でRMSEが収束する傾向が見て取れるので演算量が元素数に依存しないというのは言い過ぎかもしれないが，少なくとも元素数の二乗よりは少ないことが期待できる。

ニューラルネットワーク
^^^^^^^^^^^^^^^^^^^^^^

学習先のニューラルネットワークはn2p2と同じfeedforward neural networkであり，その実装はライブラリーなどに頼ることなくænet内で行われている。Activation functionとしてはhyperbolic tangentやsigmoid関数を用いることができるようになっている。原子間力を考慮した学習には対応していないようである。

LAMMPSとの連携
^^^^^^^^^^^^^^^^^^^^^^

n2p2と違い，LAMMPS本体に組み込まれているわけではないが，インターフェースが `ウェブサイト <https://github.com/HidekiMori-CIT/aenet-lammps>`_ において公開されており，その指示に従いインターフェースとLAMMPSをビルドすることによってænetのポテンシャルファイルをLAMMPSから利用することができる。


DeePMD-kit
~~~~~~~~~~~~

概要
^^^^^

`DeePMD-kit <https://docs.deepmodeling.com/projects/deepmd/en/r2/>`_ [8] は現在活発に開発が成されているニューラルネットワークポテンシャル作成ソフトウェアであり，GNU LGPLv3.0 Licenseのもとで配布されている。開発者らが独自に考案したDeep Potential Smooth Edition (DeepPot-SE) など特徴的な記述子を利用することができること，ニューラルネットワークの演算に `Pytorch <https://pytorch.org/>`_ を用いることによって高速なニューラルネットワークの計算ができることなどが特徴である。

記述子
^^^^^^^^^

文献[8]やウェブサイトの情報によると多くの種類の記述子を用いることができるようである。ここではDeepPot-SE記述子について紹介する。DeepPot-SEでは，まずは原子 $i$ とそれに近接する原子 $j$ の座標データを用いて以下のような行ベクトル $\\tilde{R}^i$ を作る。

$$ \\tilde{R}^i = \\left\\{ s \\left( r_{ij} \\right), \\hat{x}_{ij}, \\hat{y}_{ij}, \\hat{z}_{ij} \\right\\} $$

ここで $s\\left(r_{ij}\\right)$ は以下のような関数， $\\hat{x}_{ij} = \\frac{s\\left(r_{ij}\\right) x_{ij}}{r_{ij}}$ , $\\hat{y}_{ij} = \\frac{s\\left(r_{ij}\\right) y_{ij}}{r_{ij}}$ , $\\hat{z}_{ij} = \\frac{s\\left(r_{ij}\\right) z_{ij}}{r_{ij}}$ である。

$$ s\\left( r_{ij} \\right) = \\frac{1}{r_{ij}} (r_{ij} < r_{cs}) $$

$$ s\\left( r_{ij} \\right) = \\frac{1}{r_{ij}} \\left\\{ \\frac{1}{2} \\cos \\left[\\pi \\frac{\\left( r_{ij}-r_{cs} \\right)}{\\left( r_c - r_{cs}\\right)} \\right] + \\frac{1}{2}     \\right\\} (r_{cs}< r_{ij} < r_c) $$

$$ s\\left( r_{ij} \\right) = 0 (r_{ij}  > r_c) $$

ここで $r_c$ はカットオフ距離， $r_{cs}$ はカットオフ距離においてスムーズに0へ減衰させるためのカットオフパラメーターである。

つぎに，"embedding network" $$G\\left(s\\left(r_{ij}\\right)\\right)$$ を定義する。これは スカラー量である $$s\\left( r_{ij} \\right)$$ を $$M_1$$ 個の出力にマップするニューラルネットワークである。 $$G$$ のネットワークパラメーターは原子 $i,j$ の原子種に依存する。原子 $i$ に対してこのネットワークを作用すると原子 $i$ の近接原子の原子数を $N_i$ とすると $$N_i \\times M_1$$ の行列が得られるため，このネットワークは行列で表現することができる。そこでこのネットワークの行列表記を $G^{i1}$ とする。さらに $G^{i1}$ の最初の $M_2$ 列を抽出した行列を $G^{i2}$ とする。この二つの行列と $\\tilde{R}^i$ を用いて以下のような演算を行う。

$$ D^i = \\left( G^{i1} \\right)^T \\tilde{R}^i \\left( \\tilde{R}^i \\right)^T G^{i2} $$

最終的に得られたその大きさが $M_1 \\times M_2$ の $D^i$ という行列が原子 $i$ をあらわすDeepPot-SE記述子である（ただし行列のままでは扱いづらいため，ベクトルに展開する）Embedding networkを介して変換を施すことによって記述子が得られるようになっているため，embedding networkの設定によって非常に柔軟に記述子の大きさや多様性をコントロールすることができるのがDeepPot-SEの特徴である。

ニューラルネットワーク
^^^^^^^^^^^^^^^^^^^^^^^^

DeePMD-kitにおいては二種類のニューラルネットワークが用いられる。一つは先にも紹介した記述子を構築するためのembedding networkである。ただし文献[8]にはその詳細は記載されていない。もう一つは記述子を入力とし，エネルギーを出力とするfitting networkである。Fitting networkはskip connectionを含むfeedforward neural networkである。Pytorchをバックエンドとしているため高速な動作が期待できることなどがn2p2, ænetとの違いと言える。

LAMMPSとの連携
^^^^^^^^^^^^^^^^^^^^^^

DeePMD-kitは多くのライブラリーに依存するアプリケーションのため，ソースからビルドする難易度が非常に高い（本稿の著者は断念した）しかし，コンパイル済みのバイナリーパッケージをcondaなどから入手できるようになっており，その際同時にインストールすることができるLAMMPSはDeePMD-kitのポテンシャルファイルを利用することができる。以下のようなコマンドを実行すればよい。

::

  conda create -n deepmd deepmd-kit lammps horovod -c conda-forge


RANN
~~~~~~~~~~~~

概要
^^^^^

Rapid artificial neural network (RANN) [9] は `このGitHubのリポジトリ <https://github.com/ranndip>`_ において公開されているニューラルネットワークポテンシャル作成ソフトウェアである。記述子はMEAMポテンシャルを参考にした独自のものを採用している。特に電子スピンを考慮した記述子を用いることができる点が特徴的である。リポジトリを確認する限り，特にライセンスは設定されていないようである。

記述子
^^^^^^^^^

RANNにおいて用いることのできる記述子については文献[9]や `GitHubのリポジトリ <https://github.com/ranndip/RANN-potentials>`_ に記述されている。そのうち最も特徴的と思われるradial screened spin (2体) とbond screened spin (3体) の表式を以下に記す。文献[9]やウェブサイトの記法にならい，原子のインデックスをギリシャ文字 $\\alpha, \\beta, \\gamma$ で表す。

$$ f_i^\\alpha = \\sum_\\beta \\left( \\frac{r^{\\alpha \\beta}}{r_e} \\right)^i e^{-\\delta_i \\frac{r^{\\alpha \\beta}}{r_e}} \\left( \\bf{s}^\\alpha \\cdot \\bf{s}^\\beta \\right) f_c \\left( \\frac{r_c-r^{\\alpha \\beta}}{dr} \\right) $$

$$ f_{ij}^{\\alpha} = \\sum_{\\beta} \\sum_{\\gamma} \\left( \\cos \\left(\\theta_{\\alpha\\beta\\gamma}\\right)\\right)^i  e^{-\\delta_j \\frac{r^{\\alpha \\beta}}{r_e}}  e^{-\\delta_j \\frac{r^{\\alpha \\gamma}}{r_e}} S^{\\alpha\\beta} S^{\\alpha\\gamma} \\left( \\bf{s}^{\\alpha} \\bf{s}^{\\beta} \\right) \\left( \\bf{s}^{\\alpha} \\bf{s}^{\\gamma} \\right) f_c \\left( \\frac{r_c-r^{\\alpha \\beta}}{dr} \\right) f_c \\left( \\frac{r_c-r^{\\alpha \\gamma}}{dr} \\right)$$

式中の $r^{\\alpha\\beta}$ は原子 $\\alpha, \\beta$ 間の距離， $\\theta_{\\alpha\\beta\\gamma}$ は原子 $\\alpha, \\beta, \\gamma$ の成す角， $r_e, i, \\delta_i, dr, r_c$ はパラメーターである。また， $f_c$ はカットオフ関数であり，距離 $r_c$ において0になるようなスムーズな関数である。さらに $S^{\\alpha\\beta}$ は原子 $\\alpha, \\beta$ とその間にある原子がなす角度に依存するカットオフ関数であり，この項によって考慮すべき近接原子の数を削減することができる。最後に $\\bf{s}^\\alpha$ は原子 $\\alpha$ のスピン分極である。内積で計算するので，スピン分極がない原子も存在する場合その貢献分を補うようスピンに依存しない記述子も含める必要がある。

ニューラルネットワーク
^^^^^^^^^^^^^^^^^^^^^^^^

学習先のニューラルネットワークはn2p2, ænetと同じfeedforward neural networkであり，その実装はライブラリーなどに頼ることなくRANN内で行われている。ænet同様原子間力を考慮した学習には対応していないようである。用いることのできるactivation functionは $\\frac{x}{10}+\\frac{9}{10} \\log \\left( e^x + 1 \\right)$ という表式のもののみである。

LAMMPSとの連携
^^^^^^^^^^^^^^^^^^^^^^

RANNはLAMMPSにパッケージとして組み込まれている。そのため，LAMMPSのソースディレクトリーにおいて以下のようなコマンドを実行することによってRANNのポテンシャルファイルが使えるLAMMPSバイナリーを得ることができる。

::

  make yes-ml-rann
  make mpi

ソフトウェア比較
~~~~~~~~~~~~~~~~~~

ここまで4種類のニューラルネットワーク作成ソフトウェアを紹介したが，どれを用いるのがよいのだろうか。それぞれの特徴を鑑みながら考えてみたい。

- n2p2は最初に提案され，その後も広く使われてきたオーソドックスな手法に従ってポテンシャルを作ることができる。実績も豊富なので，いろいろな問題に安心して用いることができる。ソフトウェアのロバスト性も高い印象である。ニューラルネットワークの演算は自前で，GPUに対応しているわけでもないので計算速度はそれほど期待できない。
- ænetの記述子は元素の数にその演算量が極力依存しないように設計されている。この方針による精度の悪化も，少なくとも文献[7]においては心配する必要はないと報告されている。そのため多くの原子種が存在する系を扱いたい場合に適していると考えられる。ニューラルネットワークに関してはn2p2の場合と同様高速な動作は期待できない。
- DeePMD-kit は記述子の評価の仕方が複雑で，その分柔軟に様々な原子配置を記述することができることが期待できる。また，ニューラルネットワークの評価はPytorchを介して行うため，高速な動作が期待できる。特にGPUを用いると高速に動作する。
- RANNは電子スピンを考慮することができる点が特徴的である。原子配置は同じで各原子のスピン分極のみが異なるような系を扱うのであればここまであげたソフトウェアの中では選択肢はRANNしかない。ニューラルネットワークに関してはn2p2, ænetと同様である。
- ænet, RANNは原子間力を用いた学習には対応していないようである。原子間力を用いた学習を行うと経験上まさにその原子間力の予測性能が向上する。これは分子動力学シミュレーションに活用するにあたって重要なポイントである。ただし特にn2p2の場合原子間力を用いる学習を行うとメモリ消費量が劇的に増加するため，注意を要する。

参考文献
========

#. J\. Behler and M. Parrinello, Phys. Rev. Lett. 98, 146401 (2007).
#. Jörg Behler, International Journal of Quantum Chemistry 115, 1032 (2015)
#. Giulio Imbalzano, Andrea Anelli, Daniele Giofré, Sinja Klees, Jörg Behler, Michele Ceriotti, J. Chem. Phys. 148, 241730 (2018).
#. M\.  Gastegger, L. Schwiedrzik, M. Bittermann, F. Berzsenyi, P. Marquetand, J. Chem. Phys. 148, 241709 (2018).
#. A\.  Singraber, T. Morawietz, J. Behler and C. Dellago, J. Chem. Theory Comput. 2019, 15 (5), 3075–3092.
#. T\.  Yamasaki, A. Kuroda, T. Kato, J. Nara, J. Koga, T. Uda, K. Minami, and T. Ohno, Computer Physics Communications 244, 264-276 (2019).
#. N.\ Artrith, A. Urban, and G. Ceder, Phys. Rev. B 96, 014112 (2017).
#. J.\ Zeng et al. The Journal of Chemical Physics 159, 054801 (2023).
#. D.\ Dickel, M. Nitol, C.D. Barrett, Computational Materials Science 196, 110481 (2021).


.. |image0| image:: media/image1.png
.. |image1| image:: media/image2.svg
.. |image2| image:: media/image3.svg
.. |image3| image:: media/image4.svg
.. |image4| image:: media/image5.svg
.. |image5| image:: media/image6.svg
.. |image6| image:: media/image7.svg
.. |movie1| image:: media/image8.gif
   :width: 4.74998in
   :height: 3.97917in
